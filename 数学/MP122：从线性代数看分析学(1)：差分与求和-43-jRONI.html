<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="UTF-8">
        <title>
            MP122：从线性代数看分析学(1)：差分与求和
        </title>
        <link rel="stylesheet" type="text/css" href="print.css" media="print">
        <style type="text/css">
            *,::after,::before{box-sizing: border-box;}body{font-size: 1.2rem;line-height: 1.5em;background-color: #f6f6f6;font-family: "PT Serif", "Times New Roman", Times, serif, "Helvetica Neue", Helvetica, Arial, sans-serif;color: rgb(31, 9, 9);}.article{max-width: 50em;margin: 0px auto;padding: 6em;background: #fff;overflow: hidden;border-radius: 2px;-webkit-box-shadow: 0 1px 3px rgba(26, 26, 26, 0.1);box-shadow: 0 1px 3px rgba(26, 26, 26, 0.1);-webkit-box-sizing: border-box;box-sizing: border-box;}p{margin-bottom: 1.5em;line-height: inherit;}p img[eeimg]{display: inline-block;margin: 0 3px;max-width: 100%;vertical-align: middle;}p + ul,p + ol{margin-top: 0.5em;}blockquote{margin: 0 2em;background: #eee;border-radius: 5px;padding: 15px;color: rgb(101, 101, 101);font-style: italic;}blockquote p{background: #eee;border-radius: 5px;}blockquote p::before{content: "\201C";}blockquote p::after{content: "\201D";}blockquote ul,blockquote ol{margin-left: 0px;}blockquote::before,blockquote::after,q::before,q::after{content: none;}blockquote > :first-child,li > :first-child{margin-top: 0px;}blockquote > :last-child{margin-bottom: 0px;}blockquote,q{quotes: none;}a{cursor: pointer;text-decoration: none;color: #3ac19f;}a:hover,a:active{text-decoration: none;color: #ff6188;outline: 0px;}a.url{word-break: break-all;}table tr th{border-bottom: 0px;}table{border-collapse: collapse;border-spacing: 0px;margin-bottom: 1.5em;font-size: 1em;width: 100%;overflow: auto;break-inside: auto;text-align: left;}header,footer{font-family: "PT Serif", "Times New Roman", Times, serif;color: rgb(31, 9, 9);}thead{background-color: rgb(218, 218, 218);display: table-header-group;}thead th,tfoot th{padding: 0.25em 0.25em 0.25em 0.4em;text-transform: uppercase;}tr{break-inside: avoid;break-after: auto;}tr:nth-child(2n){background: rgb(232, 231, 231);}th{text-align: left;}td{vertical-align: top;padding: 0.25em 0.25em 0.25em 0.4em;}tt{font-size: 0.8em;line-height: 1.7em;}ol,ul{text-indent: 0;position: relative;list-style: none;margin: 0px 0px 1.5em 1.5em;}ol li{list-style-type: decimal;list-style-position: outside;}ul li{list-style-type: disc;list-style-position: outside;}li div{padding-top: 0px;}li{margin: 0px;margin-left: 2em;position: relative;}li > figure:last-child{margin-bottom: 0.5rem;}li > :first-child{margin-top: 0px;}li > ul,li > ol{margin-top: inherit;margin-bottom: 0px;}li ol > li{list-style-type: lower-alpha;}li li ol > li{list-style-type: lower-roman;}kbd{margin: 0px 0.1em;padding: 0.1em 0.6em;font-size: 0.8em;color: rgb(36, 39, 41);background: rgb(255, 255, 255);border: 1px solid rgb(173, 179, 185);border-radius: 3px;box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px,rgb(255, 255, 255) 0px 0px 0px 2px inset;white-space: nowrap;vertical-align: middle;}samp,tt{font-family: var(--monospace);}hr{border-bottom: 1px solid #d6d6d6;margin-inline-start: 15%;margin-inline-end: 15%;margin-block-start: 5rem;margin-block-end: 5rem;}u{text-decoration: none;border-bottom: 1px dashed #f40;}figure{margin: 2em auto;max-width: 100%;padding: 0px;font-size: 1rem;text-align: center;}figure img{display: block;max-width: 60%;margin: auto;}figure figcaption{padding: 0 1em;font-size: 0.9rem;color: #999;}figure > table{margin: 0px !important;}div.hr:focus{cursor: none;}a img,img a{cursor: pointer;}
        </style>
        <style type="text/css">
            .background-image{text-align: center;max-width: inherit;}.background-image img{max-width: 100%;}.video{max-width: inherit;margin: 80px auto;}.video-cover{max-width: inherit;background-color: #141216;}.video img{height: 400px;display: block;margin: 0 auto;}.video-tip{border-radius: 0 0 8px 8px;max-width: inherit;height: 34px;text-align: center;}.header{margin-bottom: 80px;}.title{font-size: 36px;margin-bottom: 80px;text-align: center;line-height: 42px;}.AuthorInfo,.Avatar{border-radius: 5px;}.Popover{width: 50px;height: 50px;}.AuthorInfo{width: 240px;margin: auto;}.AuthorInfo-content{position: relative;left: 60px;top: -50px;line-height: 1em;padding: 6px 0;}.AuthorInfo-name{font-size: 28px;}.AuthorInfo-detail{font-size: 16px;margin-top: 8px;}.Popover,.AuthorInfo,.AuthorInfo-content,.AuthorInfo{height: 50px;}.LinkCard{margin: 1em auto;width: 390px !important;border-radius: 12px;}.LinkCard-content{position: relative;display: -webkit-box;display: -ms-flexbox;display: flex;-webkit-box-align: center;-ms-flex-align: center;align-items: center;-webkit-box-pack: justify;-ms-flex-pack: justify;justify-content: space-between;padding: 12px;border-radius: inherit;background-color: hsla(0, 0%, 96.5%, 0.88);}.LinkCard-text{overflow: hidden;}.LinkCard-title{display: -webkit-box;-webkit-line-clamp: 2;-webkit-box-orient: vertical;overflow: hidden;text-overflow: ellipsis;max-height: 40px;font-size: 16px;font-weight: 500;line-height: 1.25;color: #1a1a1a;}.LinkCard-meta{display: -webkit-box;display: -ms-flexbox;display: flex;margin-top: 4px;font-size: 14px;line-height: 20px;color: #999;white-space: nowrap;}.LinkCard-imageCell{margin-left: 8px;border-radius: 6px;}.LinkCard-image{display: block;margin: 0 !important;width: 60px;height: 60px;-o-object-fit: cover;object-fit: cover;border-radius: inherit;}.LinkCard-image--default{display: -webkit-box;display: -ms-flexbox;display: flex;-webkit-box-align: center;-ms-flex-align: center;align-items: center;-webkit-box-pack: center;-ms-flex-pack: center;justify-content: center;background-color: #ebebeb;color: #d3d3d3;}svg:not(:root){overflow: hidden;}.TipCard,.LinkCard{position: relative;display: block;width: inherit;-webkit-box-sizing: border-box;box-sizing: border-box;max-width: 100%;overflow: hidden;text-indent: 0 !important;}.TipCard,.LinkCard,.TipCard:hover,.LinkCard:hover{text-decoration: none;border: none !important;color: inherit !important;}.TipCard-backdrop,.LinkCard-backdrop{position: absolute;top: 0;left: 0;right: 0;bottom: 0;background-repeat: no-repeat;-webkit-filter: blur(20px);filter: blur(20px);background-size: cover;background-position: 50%;}.divide{height: 30px;max-width: 45em;margin: 0 auto;}.reference{text-indent: 0;font-size: 14px;}.reference tr:nth-child(2n){background: white;}
        </style>
    </head>
    <body>
        <div class="article">
            <div class="header">
                <div class="background-image">
                    <img src="https://pic4.zhimg.com/v2-63df84ebd23341bb3f7ed5e362ebd8a1_720w.jpg?source=172ae18b" alt="background image">
                </div>
                <div class="title">
                    <a href="https://zhuanlan.zhihu.com/p/49940453" target="_blank">
                        MP122：从线性代数看分析学(1)：差分与求和
                    </a>
                </div>
                <a class="UserLink-link" target="_blank" href="https://www.zhihu.com/people/smdw">
                    <div class="AuthorInfo">
                        <div class="Popover">
                            <img class="Avatar" width="50" height="50" src="https://pic2.zhimg.com/v2-c4aa9b3e46782eb49a182cd7ed914acf.jpg?source=172ae18b" alt="头像">
                        </div>
                        <div class="AuthorInfo-content">
                            <div class="AuthorInfo-name">
                                <span>
                                    jRONI
                                </span>
                            </div>
                            <div class="AuthorInfo-detail">
                                <span>
                                    2019-08-24
                                </span>
                            </div>
                        </div>
                    </div>
                </a>
            </div>
            <div class="text">
                <p>
                    函数
                    <img src="https://www.zhihu.com/equation?tex=f%3A+%5Cmathbb+R+%5Cto+%5Cmathbb+R" alt="f: \mathbb R \to \mathbb R" eeimg="1">
                    对变量均匀等分离散化后，构成时间序列，取其中的一段由
                    <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1">
                    个点构成向量，用列向量记为
                    <img src="https://www.zhihu.com/equation?tex=x+%3D+%5Bx_i%5D+%5Cin+%5Cmathbb+R%5En" alt="x = [x_i] \in \mathbb R^n" eeimg="1">
                    。现在用线性代数来讨论离散形式的微积分。
                </p>
                <h2>
                    差分算子
                </h2>
                <p>
                    将线性空间
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En+%5Cin+%5Ctext%7BOb%7D%28%5Ctextbf%7BVct%7D%29" alt="\mathbb R^n \in \text{Ob}(\textbf{Vct})" eeimg="1">
                    上的线性自同态集合记为
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BEnd%7D%28%5Cmathbb+R%5En%29+%5Csimeq+%5Ctext%7BHom%7D%28%5Cmathbb+R%5En%2C%5Cmathbb+R%5En%29++%5Cin+%5Ctext%7BOb%7D%28%5Ctextbf%7BVct%7D%29+%5C%5C" alt="\text{End}(\mathbb R^n) \simeq \text{Hom}(\mathbb R^n,\mathbb R^n)  \in \text{Ob}(\textbf{Vct}) \\" eeimg="1">
                </p>
                <p>
                    易于证明如下定义的
                    <b>
                        差分算子(difference operator)
                    </b>
                    是其中的一个自态射：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+%5Cmathbb+R%5En+%26%5Cxrightarrow%7B%5CDelta%7D+%5Cmathbb+R%5En+%5Cnonumber+%5C%5C+%5Bx_i%5D+%26%5Cmapsto+%5CDelta+%5Bx_i%5D++%3D+%5CDelta+%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%3D+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+-+x_1+%5C%5C+x_3+-+x_2+%5C%5C+%5Cvdots+%5C%5C+x_n+-+x_%7Bn-1%7D+%5Cend%7Bbmatrix%7D+%5Cend%7Balign%7D+%5Ctag%7B1%7D" alt="\begin{align} \mathbb R^n &amp;\xrightarrow{\Delta} \mathbb R^n \nonumber \\ [x_i] &amp;\mapsto \Delta [x_i]  = \Delta \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} = \begin{bmatrix} 0 \\ x_2 - x_1 \\ x_3 - x_2 \\ \vdots \\ x_n - x_{n-1} \end{bmatrix} \end{align} \tag{1}" eeimg="1">
                </p>
                <p>
                    上式可以展开为矩阵乘法：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+-+x_1+%5C%5C+x_3+-+x_2+%5C%5C+%5Cvdots+%5C%5C+x_n+-+x_%7Bn-1%7D+%5Cend%7Bbmatrix%7D+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+0+%26+-1+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-1+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+0+%26+-1+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D+%5Ccirc++%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D++%5Ctag%7B2%7D" alt="\begin{bmatrix} 0 \\ x_2 - x_1 \\ x_3 - x_2 \\ \vdots \\ x_n - x_{n-1} \end{bmatrix} = \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -1 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 0 &amp; -1 &amp; 1 \\ \end{bmatrix} \circ  \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix}  \tag{2}" eeimg="1">
                </p>
                <p>
                    即作为有限维的线性映射，差分算子具有如下的矩阵表示：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+0+%26+-1+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-1+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+0+%26+-1+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D++%5Ctag%7B3%7D" alt="\Delta = \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -1 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 0 &amp; -1 &amp; 1 \\ \end{bmatrix}  \tag{3}" eeimg="1">
                </p>
                <h2>
                    二阶差分
                </h2>
                <p>
                    线性自同态
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta+%5Cin+%5Ctext%7BEnd%7D%28%5Cmathbb+R%5En%29" alt="\Delta \in \text{End}(\mathbb R^n)" eeimg="1">
                    的复合仍然是线性自同态，直接计算二阶差分算子有：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta%5E2+%3D+%5CDelta+%5Ccirc+%5CDelta+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+0+%26+-1+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-1+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+0+%26+-1+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D%5E2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+1+%26+-2+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-2+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+1+%26+-2+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D++%5C%5C" alt="\Delta^2 = \Delta \circ \Delta = \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -1 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 0 &amp; -1 &amp; 1 \\ \end{bmatrix}^2 = \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 1 &amp; -2 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -2 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 1 &amp; -2 &amp; 1 \\ \end{bmatrix}  \\" eeimg="1">
                </p>
                <p>
                    相当于对差分再做一次差分：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+%5Cmathbb+R%5En+%26%5Cxrightarrow%7B%5CDelta%5E2%7D+%5Cmathbb+R%5En+%5Cnonumber+%5C%5C+%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%26%5Cmapsto+%5CDelta%5E2+%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%5Cnonumber+%5C%5C+%26%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+0+%26+-1+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-1+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+0+%26+-1+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D%5E2+%5Ccirc++%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%5Cnonumber+%5C%5C+%26%3D+%5Cbegin%7Bbmatrix%7D+0+%26+0+%26+0++%5C%5C+-1+%26+1+%26+0+%5C%5C+1+%26+-2+%26+1+%5C%5C++%26+%26+%26+%26+%5Cddots+%5C%5C++%26+%26+%26+%26+-2+%26+1+%26+0+%5C%5C++%26+%26+%26+%26+1+%26+-2+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D+%5Ccirc++%5Cbegin%7Bbmatrix%7D+x_1+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%5Cnonumber+%5C%5C+%26%3D+%5CDelta+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+-+x_1+%5C%5C+x_3+-+x_2+%5C%5C+%5Cvdots+%5C%5C+x_n+-+x_%7Bn-1%7D+%5Cend%7Bbmatrix%7D+%3D+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+-+x_1+%5C%5C+%28x_3+-+x_2%29-%28x_2+-+x_1%29+%5C%5C++%5Cvdots+%5C%5C++%28x_n+-+x_%7Bn-1%7D%29+-+%28x_%7Bn-1%7D+-+x_%7Bn-2%7D%29+%5Cend%7Bbmatrix%7D+%3D+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+-+x_1+%5C%5C+x_3+-+2x_2+%2B+x_1+%5C%5C++%5Cvdots+%5C%5C++x_n+-+2x_%7Bn-1%7D+%2B+x_%7Bn-2%7D+%5Cend%7Bbmatrix%7D+%5Cend%7Balign%7D" alt="\begin{align} \mathbb R^n &amp;\xrightarrow{\Delta^2} \mathbb R^n \nonumber \\ \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} &amp;\mapsto \Delta^2 \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} \nonumber \\ &amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -1 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 0 &amp; -1 &amp; 1 \\ \end{bmatrix}^2 \circ  \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} \nonumber \\ &amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0  \\ -1 &amp; 1 &amp; 0 \\ 1 &amp; -2 &amp; 1 \\  &amp; &amp; &amp; &amp; \ddots \\  &amp; &amp; &amp; &amp; -2 &amp; 1 &amp; 0 \\  &amp; &amp; &amp; &amp; 1 &amp; -2 &amp; 1 \\ \end{bmatrix} \circ  \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} \nonumber \\ &amp;= \Delta \begin{bmatrix} 0 \\ x_2 - x_1 \\ x_3 - x_2 \\ \vdots \\ x_n - x_{n-1} \end{bmatrix} = \begin{bmatrix} 0 \\ x_2 - x_1 \\ (x_3 - x_2)-(x_2 - x_1) \\  \vdots \\  (x_n - x_{n-1}) - (x_{n-1} - x_{n-2}) \end{bmatrix} = \begin{bmatrix} 0 \\ x_2 - x_1 \\ x_3 - 2x_2 + x_1 \\  \vdots \\  x_n - 2x_{n-1} + x_{n-2} \end{bmatrix} \end{align}" eeimg="1">
                </p>
                <p>
                    类似的可以得到高阶差分的矩阵表示。
                </p>
                <h2>
                    等价划分
                </h2>
                <p>
                    不仅可以在线性空间
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En" alt="\mathbb R^n" eeimg="1">
                    上定义差分算子，还可以将其拓展到仿射空间上，若
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En" alt="\mathbb R^n" eeimg="1">
                    是仿射空间
                    <img src="https://www.zhihu.com/equation?tex=A%5En" alt="A^n" eeimg="1">
                    的平移空间，则可以类似以上定义差分算子
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta%3A+A%5En+%5Cto+%5Cmathbb+R%5En" alt="\Delta: A^n \to \mathbb R^n" eeimg="1">
                    。显然，仿射空间
                    <img src="https://www.zhihu.com/equation?tex=A%5En" alt="A^n" eeimg="1">
                    上叠加一个常数
                    <img src="https://www.zhihu.com/equation?tex=c+%5Cin+%5Cmathbb+R%5En" alt="c \in \mathbb R^n" eeimg="1">
                    不会影响差分的结果，即
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta+a+%3D+%5CDelta+%28a+%2B+c%29" alt="\Delta a = \Delta (a + c)" eeimg="1">
                    ，这一关系是一种等价关系，记为
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=a+%5Csim+a%2Bc+%5CLeftrightarrow+%5Coverline+a+%3D+%5Coverline%7Ba%2Bc%7D+%5Cin+A%5En%2F%5Csim+%5Ctag%7B4%7D" alt="a \sim a+c \Leftrightarrow \overline a = \overline{a+c} \in A^n/\sim \tag{4}" eeimg="1">
                </p>
                <p>
                    这里用上划线
                    <img src="https://www.zhihu.com/equation?tex=%5Coverline+x" alt="\overline x" eeimg="1">
                    表示以
                    <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1">
                    为代表的等价类。
                </p>
                <p>
                    差分构造了集合的划分，这一等价的关系是分析学的一个基础概念。注意到差分算子
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta+%5Cin+%5Ctext%7BEnd%7D%28%5Cmathbb+R%5En%29" alt="\Delta \in \text{End}(\mathbb R^n)" eeimg="1">
                    不是
                    <b>
                        单同态(monomorphism)
                    </b>
                    ，其矩阵表示(3)是不可逆的。对于并非是单同态的映射，通常可以用等价划分的方式来研究。在
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En" alt="\mathbb R^n" eeimg="1">
                    中以相同的差分作为等价关系：
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta+x+%3D+%5CDelta+y+%5CLeftrightarrow+x+%5Csim+y+%5CLeftrightarrow+%5Coverline+x+%3D+%5Coverline+y+%5Cin+%5Cmathbb+R%5En%2F%5Csim+%5C%5C" alt="\Delta x = \Delta y \Leftrightarrow x \sim y \Leftrightarrow \overline x = \overline y \in \mathbb R^n/\sim \\" eeimg="1">
                </p>
                <p>
                    这样构成了对
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En" alt="\mathbb R^n" eeimg="1">
                    的一个
                    <b>
                        划分(partition)
                    </b>
                    。
                    <img src="https://www.zhihu.com/equation?tex=%5Cforall+c+%5Cin+%5Cmathbb+R" alt="\forall c \in \mathbb R" eeimg="1">
                    ，令
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bbmatrix%7D+y_1+%5C%5C+%5Cvdots+%5C%5C+y_n+%5Cend%7Bbmatrix%7D++%3D+%5Cbegin%7Bbmatrix%7D+x_1+%2B+c+%5C%5C+%5Cvdots+%5C%5C+x_n+%2B+c+%5Cend%7Bbmatrix%7D+%5C%5C" alt="\begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix}  = \begin{bmatrix} x_1 + c \\ \vdots \\ x_n + c \end{bmatrix} \\" eeimg="1">
                </p>
                <p>
                    易于验证
                    <img src="https://www.zhihu.com/equation?tex=x+%5Csim+y" alt="x \sim y" eeimg="1">
                    。即向量的每个元素之间若相差一个固定的常数，则两个向量具有相同的差分，在微积分中，这一现象就是体现为不定积分中原函数的常数符号。
                </p>
                <p>
                    通过差分算子
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta" alt="\Delta" eeimg="1">
                    诱导出的等价划分(4)，得到一个
                    <b>
                        满射(surjective map)
                    </b>
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+%5Cmathbb+R%5En+%26%5Cto+%5Cmathbb+R%5En%2F%5Csim+%5Cnonumber+%5C%5C+x+%26%5Cmapsto+%5Coverline+x+%5Cnonumber+%5Cend%7Balign%7D+%5Ctag%7B5%7D" alt="\begin{align} \mathbb R^n &amp;\to \mathbb R^n/\sim \nonumber \\ x &amp;\mapsto \overline x \nonumber \end{align} \tag{5}" eeimg="1">
                </p>
                <p>
                    称为
                    <b>
                        正则投影(canonical projection)
                    </b>
                    。
                </p>
                <h2>
                    求和算子
                </h2>
                <p>
                    下式给出了差分算子的逆运算
                </p>
                <p>
                    <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+%5Cmathbb+R%5En+%26%5Cxrightarrow%7B%5CSigma%7D+%5Cmathbb+R%5En+%5Cnonumber+%5C%5C+%5Bx_i%5D+%26%5Cmapsto+%5CSigma+%5Bx_i%5D++%3D+%5CSigma+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+%5C%5C+x_3+%5C%5C+%5Cvdots+%5C%5C+x_n+%5Cend%7Bbmatrix%7D+%3D+%5Cbegin%7Bbmatrix%7D+x%5E%2A+%5C%5C+x%5E%2A+%2B+x_2+%5C%5C+x%5E%2A+%2B+x_2+%2B+x_3+%5C%5C+%5Cvdots+%5C%5C+x%5E%2A+%2B+x_2+%2B+x_3+%2B+%5Cdots+%2B+x_n+%5Cend%7Bbmatrix%7D+%5Cnonumber+%5C%5C+%26%3D+%5Cbegin%7Bbmatrix%7D+0+%5C%5C+x_2+%5C%5C+x_2+%2B+x_3+%5C%5C+%5Cvdots+%5C%5C+x_2+%2B+x_3+%2B+%5Cdots+%2B+x_n+%5Cend%7Bbmatrix%7D+%2B+%5Cbegin%7Bbmatrix%7D+x%5E%2A+%5C%5C+x%5E%2A+%5C%5C+x%5E%2A++%5C%5C+%5Cvdots+%5C%5C+x%5E%2A+%5Cend%7Bbmatrix%7D+%5Cend%7Balign%7D" alt="\begin{align} \mathbb R^n &amp;\xrightarrow{\Sigma} \mathbb R^n \nonumber \\ [x_i] &amp;\mapsto \Sigma [x_i]  = \Sigma \begin{bmatrix} 0 \\ x_2 \\ x_3 \\ \vdots \\ x_n \end{bmatrix} = \begin{bmatrix} x^* \\ x^* + x_2 \\ x^* + x_2 + x_3 \\ \vdots \\ x^* + x_2 + x_3 + \dots + x_n \end{bmatrix} \nonumber \\ &amp;= \begin{bmatrix} 0 \\ x_2 \\ x_2 + x_3 \\ \vdots \\ x_2 + x_3 + \dots + x_n \end{bmatrix} + \begin{bmatrix} x^* \\ x^* \\ x^*  \\ \vdots \\ x^* \end{bmatrix} \end{align}" eeimg="1">
                </p>
                <p>
                    这就是求和算子，即积分算子的有限维原形。去掉常数项后，求和算子具有矩阵表示，它也是线性算子，记
                    <img src="https://www.zhihu.com/equation?tex=%5CSigma+%5Cin+%5Ctext%7BEnd%7D%28%5Cmathbb+R%5En%29" alt="\Sigma \in \text{End}(\mathbb R^n)" eeimg="1">
                    。
                </p>
                <p>
                    对比(5)中的正则投影可见，求和算子相当于正则投影的逆运算。在连续函数的微积分中，这一关系即是求导和求不定积分的关系。
                </p>
                <h2>
                    讨论
                </h2>
                <p>
                    以上讨论了
                    <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1">
                    个点离散化后构成的有限时间序列，将其纳入
                    <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1">
                    维线性空间
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R%5En+%5Cin+%5Ctext%7BOb%7D%28%5Ctextbf%7BVct%7D%29" alt="\mathbb R^n \in \text{Ob}(\textbf{Vct})" eeimg="1">
                    中，用纯线性代数的方式讨论了差分算子
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta" alt="\Delta" eeimg="1">
                    和求和算子
                    <img src="https://www.zhihu.com/equation?tex=%5CSigma" alt="\Sigma" eeimg="1">
                    ，且
                    <img src="https://www.zhihu.com/equation?tex=%5CDelta%2C+%5CSigma+%5Cin+%5Ctext%7BEnd%7D%28%5Cmathbb+R%5En%29" alt="\Delta, \Sigma \in \text{End}(\mathbb R^n)" eeimg="1">
                    。不严格地说，当
                    <img src="https://www.zhihu.com/equation?tex=%5Clim+n+%5Cto+%5Cinfty" alt="\lim n \to \infty" eeimg="1">
                    且将物体延拓到整个
                    <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+R" alt="\mathbb R" eeimg="1">
                    之后，我们实现了对函数
                    <img src="https://www.zhihu.com/equation?tex=f%3A+%5Cmathbb+R+%5Cto+%5Cmathbb+R" alt="f: \mathbb R \to \mathbb R" eeimg="1">
                    的某种逼近，问题必须置于一个无穷维的线性空间
                    <img src="https://www.zhihu.com/equation?tex=V+%5Cin+%5Ctext%7BOb%7D%28%5Ctextbf%7BVct%7D%29" alt="V \in \text{Ob}(\textbf{Vct})" eeimg="1">
                    中讨论。此时差分算子和求和算子，在无穷维护的线性空间中构成了求导算子和积分算子，它们都是
                    <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BEnd%7D%28V%29" alt="\text{End}(V)" eeimg="1">
                    中的线性算子，对它们的研究构成了泛函分析的一个主题。
                </p>
                <p>
                </p>
                <p>
                </p>
            </div>
        </div>
    </body>
</html>
